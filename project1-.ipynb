{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef03a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the root directory and categories\n",
    "categories = ['Gothic', 'Modern', 'Mughal', 'Neoclassical', 'Pagodas', 'Pyramids']\n",
    "\n",
    "# Define the landmarks for each category\n",
    "landmarks = {'Gothic': ['ChartresCathedral', 'Notre-DameCathedral','MilanCathedral','St.VitusCathedral','CologneCathedral'],\n",
    "             'Modern': ['Cathedral of Brasilia', 'CCTV Headquarters', 'eiffel', 'Chrysler Building', 'Hallgromskirkja'],\n",
    "             'Mughal': ['Bibi Ka Maqbara', 'Jama Masjid', 'Taj Mahal', 'Tomb of Akbar', 'Tomb of I_timad-ud-Daulah'],\n",
    "             'Neoclassical': ['Academy of Athens', 'Buckingham Palace', 'Concertgebouw', 'PanthCon', 'Ripon Building'],\n",
    "             'Pagodas': ['FogongTemplePagoda','GiantWildGoosePagoda','ShwedagonPagoda','ThienMuPagoda','TianningTemplePagoda'],\n",
    "             'Pyramids': ['El Castillo, Chichen Itza','Louvre Pyramid','Pyramid of Djoser','Pyramid of Giza'\n",
    "                         ,'Santa Cecilia Acatitlan Pyramid']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adee82bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_path = \"../Landmarks\"\n",
    "\n",
    "# Define the path to the directory where the split dataset will be stored\n",
    "split_path = \"../Landmarks\"\n",
    "\n",
    "# Define the split ratios\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Loop through each category in the landmarks dictionary\n",
    "for category, landmarks in landmarks.items():\n",
    "    # Create the category directories in the split dataset\n",
    "    train_category_path = os.path.join(split_path, \"train\", category)\n",
    "    test_category_path = os.path.join(split_path, \"test\", category)\n",
    "    os.makedirs(train_category_path, exist_ok=True)\n",
    "    os.makedirs(test_category_path, exist_ok=True)\n",
    "\n",
    "    # Loop through each landmark in the category\n",
    "    for landmark in landmarks:\n",
    "        # Create the landmark directories in the split dataset\n",
    "        train_landmark_path = os.path.join(train_category_path, landmark)\n",
    "        test_landmark_path = os.path.join(test_category_path, landmark)\n",
    "        os.makedirs(train_landmark_path, exist_ok=True)\n",
    "        os.makedirs(test_landmark_path, exist_ok=True)\n",
    "\n",
    "        # Get the path to the images for the landmark\n",
    "        landmark_path = os.path.join(dataset_path, category, landmark)\n",
    "        images = os.listdir(landmark_path)\n",
    "\n",
    "        # Shuffle the images\n",
    "        random.shuffle(images)\n",
    "\n",
    "        # Calculate the number of images for the train and test sets\n",
    "        num_train_images = int(len(images) * train_ratio)\n",
    "        num_test_images = len(images) - num_train_images\n",
    "\n",
    "        # Copy the images to the train and test sets\n",
    "        for i, image in enumerate(images):\n",
    "            src_path = os.path.join(landmark_path, image)\n",
    "            if i < num_train_images:\n",
    "                dst_path = os.path.join(train_landmark_path, image)\n",
    "            else:\n",
    "                dst_path = os.path.join(test_landmark_path, image)\n",
    "            shutil.copyfile(src_path, dst_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23bbf580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 313 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20, # Randomly rotate the image up to 20 degrees\n",
    "    width_shift_range=0.1, # Randomly shift the image horizontally by up to 10% of the width\n",
    "    height_shift_range=0.1, # Randomly shift the image vertically by up to 10% of the height\n",
    "    zoom_range=0.1, # Randomly zoom the image up to 10%\n",
    "    horizontal_flip=True, # Randomly flip the image horizontally\n",
    "    vertical_flip=False, # Don't randomly flip the image vertically\n",
    "    rescale=1./255 # Rescale the pixel values to between 0 and 1\n",
    ")\n",
    "train_dir=\"../Landmarks/train\"\n",
    "# Load the training data using the ImageDataGenerator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, # Directory of the training data\n",
    "    target_size=(224, 224), # Resize the images to 224 x 224\n",
    "    batch_size=32, # Train the model on batches of 32 images at a time\n",
    "    class_mode='categorical' # Use categorical_crossentropy as the loss function for categorical classification\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc1efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
