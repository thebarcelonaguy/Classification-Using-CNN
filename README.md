# DSCI-552-project
DSCI552 group project
This repository contains my code for classification of categpries 
Title: Classification of Categories and Landmarks with CNN

Abstract:
Convolutional Neural Networks (CNNs) are a class of deep learning models that have been widely used in the field of computer vision. They are specifically designed to process and classify images, by automatically learning patterns and features from the input data. CNNs consist of multiple layers, including convolutional layers, pooling layers, and fully connected layers, which work together to extract increasingly complex representations of the input image. With their ability to automatically learn features from raw data, CNNs have achieved state-of-the-art results in a wide range of computer vision tasks, such as object detection, image segmentation, and image classification. Transfer learning is a technique in machine learning where a pre-trained model is used as a starting point for a new task. The idea behind transfer learning is that a model trained on a large dataset can be used as a feature extractor for a smaller dataset. Transfer learning has become an important area of research in deep learning, as it enables faster training of models and improved accuracy in many applications. The pre-trained model can be fine-tuned on the new dataset by updating the Iights of the last few layers or by adding new layers to the model. 
In this project, I present a novel machine-learning application that utilizes CNNs and transfer learning to classify images of famous landmarks based on their categories and individual names, and I demonstrate the effectiveness of this approach through extensive experiments and evaluations.

Introduction:

The ability to automatically classify images is a critical task for a wide range of applications, from security surveillance to social media marketing. In this report, I explore the use of transfer learning for image classification using the EfficientNetB0 and VGG16 pre-trained models. Specifically, I focus on the landmark dataset, which is organized into six categories and contains 30 landmarks with 14 images each. Due to the small size of the dataset, I experiment with various techniques, such as data augmentation and model combination, to improve the accuracy of both category and landmark classification tasks. The results of our experiments will provide insights into the effectiveness of transfer learning and the potential benefits of combining models for different image classification tasks. In addition to exploring transfer learning and data augmentation techniques, I also investigate the potential benefits of using a one-stage model versus a two-stage model for landmark and category classification tasks. A one-stage model simultaneously predicts both the category and the landmark of an image, while a two-stage model first predicts the category and then uses this information to refine the landmark prediction. We aim to determine whether the two-stage model, which incorporates additional information from the category prediction, improves the landmark classification task or vice versa. By comparing the performance of these two different models, I can gain insights into how to effectively combine multiple image classification tasks and ultimately improve the accuracy of image classification systems. The landmark dataset contains 420 images in total, with 14 images per landmark. Each image is resized to a fixed size of 224x224 and is preprocessed by subtracting the mean pixel intensity value from each color channel. The dataset is split into a training set and a validation set with a 80:20 ratio. The code for building the image classification model is implemented using TensorFlow and Keras. We use the EfficientNetB0 pre-trained models as the base model for transfer learning. A global average pooling layer is added to the output of the base model to reduce the number of parameters in the model. A fully connected layer with a softmax activation function is then added to the output of the global average pooling layer to predict the category or landmark of the input image. To avoid overfitting the model, all layers of the base model are frozen and only the fully connected layer is trained during the initial training phase. We experiment with different learning rates, optimizers, and number of epochs to find the best hyperparameters for the model. Additionally, I use data augmentation techniques such as random rotation, zooming, and horizontal flipping to generate additional training images and improve the generalization performance of the model. To evaluate the performance of the model, I use the categorical cross-entropy loss function and accuracy as the evaluation metric. We report the accuracy of both category and landmark classification on the validation set. Overall, by exploring transfer learning, data augmentation, and model combination techniques, I aim to build an accurate and robust image classification model for the landmark dataset.


Methods:

Due to the small number of training samples available, I used a 80:20 separation of training set and validation set prior to the training process. It seems at first a waste of the precious samples given, and cross validation may be a better way; But with such a small dataset, even with cross validation, after enough training the model still sees the full dataset, at which point the cross validation set fails to indicate overfitting. Since fighting overfitting is our main concern here, I choose to use a dedicated validation set. To further reduce the possibility of overfitting, I incorporate a combination of data augmentation techniques, including horizontal flip, rotation and contrast correction. Vertical flip is not used here because for most landmark pictures it does not preserve the spatial features. Into the model structure part, the main method used in the classification tasks is transfer learning. For both the category and landmark classification, I use EfficientNetB0 as the backbone of our model structure. The input images are resized to 224x224 to comply with the original network dimensions. The original structure is mostly unchanged, except for the last few layers: after the last convolution layer, a global average pooling layer is used to flatten the width and height dimensions. After that I directly attach a dense layer with the output size equal to the number of classes, finalizing the classification. Originally, betIen the global average pooling and the dense layer, EfficientNetB0 has a dropout layer; We tried to add it as Ill, but didnâ€™t see an improvement of accuracy. This is mostly due to the fact that, in the original network where every layer is trainable, the dropout layer mostly contributes to the robustness of the convolution layer before it, not the dense layer after it. Thus our model is essentially a linear classification model: The backbone of EfficientNetB0 works as a pre-trained feature extractor that converts the image into a linear array of features, then the dense layer is simply doing linear classification on these features. With a backbone poIrful enough like EfficientNetB0 or VGG16 with pre-trained Iights, an image classification task is simplified into linear classification of features. For the training part, I use a simple SGD with momentum. The learning rate is set to a quite large 0.1 since most part of the network is pre-trained and also for the speed of convergence. For both of the tasks, the classifier can achieve over 90% accuracy on the validation set. Overfitting is observed (the loss on the validation set rises) when the network is trained for more epochs, in which case I early stop manually. As for the two different tasks, category classification and landmark classification, I actually treat them as distinct tasks and train two distinct output layers accordingly. This is mostly due to the belief that the backbone is strong enough for any classification to be based on it. Since I are given just a picture and asked to predict the category and the landmark, it's best that I predict the landmark directly, since the first stage classification might already be wrong in a two-stage setting. HoIver, if I are given a picture and a category label and asked to predict the landmark, it makes more sense to separate the model into two stages to fully utilize the ground truth given.

Conclusions/Discussions:

The classification report on the validation set is as follows:


As for the test set on Vocareum, I achieved 0.97 and 0.87 respectively for the f1 score of the two tasks. 

In conclusion, this report outlines the approach taken for image classification tasks, specifically for category and landmark classification, with a small dataset. Due to the limited number of training samples, a dedicated validation set was used to prevent overfitting. Data augmentation techniques, including horizontal flip, rotation, and contrast correction, Ire employed to reduce overfitting further. Transfer learning was utilized with EfficientNetB0 as the backbone for the model structure. The model was trained with SGD with momentum and early stopping to prevent overfitting. The two different tasks, category and landmark classification, Ire treated as distinct tasks, and two separate output layers Ire trained accordingly. Overall, the results indicate that the model achieved over 90% accuracy on the validation set for both tasks, demonstrating the effectiveness of the approach taken for image classification with a small dataset. Finally, it is important to note that the results presented in this report are based on a small dataset, and therefore the performance of the model may not be representative of its performance on a larger dataset.
As such, further validation and testing on larger datasets are necessary to confirm the generalizability and scalability of the approach taken. HoIver, the promising results obtained with this approach indicate its potential to be used in a wide range of image classification applications, including in the field of computer vision, autonomous driving, and medical imaging. This report presents a comprehensive approach to image classification tasks, which includes the use of transfer learning, data augmentation, early stopping, and dedicated validation sets to prevent overfitting and achieve high accuracy. The effectiveness of this approach is demonstrated through the successful classification of categories and landmarks with over 90% accuracy on the validation set. While there is room for further improvement and validation on larger datasets, the results obtained with this approach indicate its potential to be applied to a wide range of image classification problems, with potential implications for various fields such as computer vision, autonomous driving, and medical imaging.







